---
title: "`bnmonitor`: Checking the Robustness and Sensitivity of Bayesian Networks"
author: 'Dr. Rachel Wilkerson <br> Founder at <a href="https://www.tesserwell.co/">Tesserwell, LLC</a> <br> <a href="https://github.com/rachwhatsit"><i class="fa fa-github fa-fw"></i>&nbsp; rachwhatsit</a><br> <a href="https://twitter.com/rlwilkerson?lang=en"> <i class="fa fa-twitter fa-fw"></i> &nbsp; @rlwilkerson</a><br> <a href="mailto:rachelw52@gmail.com"> <i class="fa fa-paper-plane fa-fw"></i>&nbsp; rachel.lynne.wilkerson@gmail.com</a><br>'
date: 2021-07-09 &ensp; <img src="user-logo-color.png" alt="drawing" width="100"/>  <br><br> Slides available at <http://bit.ly/infer-useR>  <br> Package webpage at <https://cran.r-project.org/web/packages/bnmonitor/index.html>
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      css: ["useR", "useR-fonts"]

---

```{r, load_refs, include=FALSE, cache=FALSE}

options(htmltools.dir.version = FALSE)
library(RefManageR)
BibOptions(check.entries = FALSE, bib.style = "authoryear", style = "markdown",
           dashed = TRUE)
bib <- ReadBib("/Users/eusa/Documents/useRbnmntr/Bib.bib")

```
 
# Package Overview

- `bnmonitor` provides a suite of diagnostic monitors that can be used in increasing fineness to check the **accuracy of forecasts** flowing from a model 

- The sensitivity functions check the **effect of changes to the probability distributions**

- Robustness monitors work on BNs learned from data

- Sensitivity monitors work on BNs learned either from data or elicitation. Data can be either discrete or continous.

---

#Example: Diabetes 

We illustrate our package with what the UCI Repository refers to as the Pima Indian dataset. 
It consists of 392 observation with the following variables, discretized according to `{r Citet(bib, "Nojavan2017")}`:
 
- PREG: number of times pregnant (low/high)

- GLUC: plasma glucose concentration (low/high)

- PRES: diastolic blood pressure (low/high)

- TRIC: triceps skin fold thickness (low/high)

- INS: 2-hour serum insulin (low/high)

- MASS: body mass index (low/high)

- PED: diabetes pedigree function (low/high)

- AGE: age (low/high)

- DIAB: test for diabetes (neg/pos)

---

background-image: url("libs/img/women-Pima-shinny-game-field-hockey.jpeg")
background-position: contain
class: center, bottom, inverse

We chose this dataset as it best showcases our monitors. However, we acknowledge that we are using the data without the explicit consent of or compensation for the original Akimel O’odham participants. For more information see `r Citet(bib, "radin2017digital")`.

???
Image credit: [Britannica](https://www.britannica.com/topic/Pima-people)

---
class: inverse, center, middle

# Robustness 

---
class: center, middle 

# Prequential = Sequential + predictions `r emo::ji("crystal_ball")`


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)

library("bnmonitor")
library("bnlearn")
library("qgraph")
library("ggplot2")
library("emo")

load("diabetes.RData")
```



---
# Bayesian Network 


.pull-left[
```{r daghc, eval=TRUE,fig.height=8,fig.retina=5,out.height="75%", out.width="90%"}
dag  <- hc(diabetes)
qgraph(dag)
```
]

.pull-right[
```{r dagmmhc, eval=TRUE,fig.height=8,fig.retina=5,out.height="75%", out.width="90%"}
dag2  <- mmhc(diabetes)
qgraph(dag2)
```
]

???

can compute the BF in bnlearn package, ours shows the contributions
---
# Global monitors 

``` {r glb}
glb.mon <- global_monitor(dag = dag , df = diabetes,alpha=2)
glb.mon2 <- global_monitor(dag = dag2 , df = diabetes,alpha=2)
glb <- as.data.frame(cbind(glb.mon$Global_Monitor$Vertex, glb.mon$Global_Monitor$Score, glb.mon2$Global_Monitor$Score, glb.mon$Global_Monitor$Score/glb.mon2$Global_Monitor$Score))
colnames(glb) <- c("Vertex", "dag_hc","dag_mmhc","bf_vertex")
knitr::kable(glb, format = 'html')
```
]
- $\alpha$ is commonly set as the maximum number of levels for a node in the dataset

???
global monitors are used to compare moodels
---
# Prequential Monitors 

- Prequential monitors were first developed by `r Citet(bib, "Dawid1992")` and refined inin `r Citet(bib, "Cowell2006","Cowell2007")`.

- $p_i$ gives the predictive density of the BN learned using the dataset $x_{[i-1]}$ including only the first $i-1$-th observations

- the level of surprise `r emo::ji("astonished_face")` of observing the value $y_j\in\mathbb{Y}_j$ for the $j$-th variable after having processed $i$ observations is:  
$$S_{ij} = -\log(p_i(y_j)))$$

- We use the logarithmic score function here, but other score functions can certainly be substituted 

---

```{r eval=require('DT'), tidy=FALSE,echo=FALSE}
DT::datatable(
  head(diabetes, 10),
  fillContainer = FALSE, options = list(pageLength = 8)
)
```

??? 

j indicates the values high/low and i indicates the node of interest.


---
# Standardization


- Relative standardization compares the log likelihood contributions to two different models. 

--

- Absolute standardization computes a Z-statistic using the following expectation and variance:

--

- $$E_{ij} = \sum_{y_j\in\mathbb{Y}_j}p_i(y_j)\log(p_i(y_j))$$

- $$V_{ij}=\sum_{y_j\in\mathbb{Y}_j}p_i(y_j)\log(p_i(y_j))^2-E_{ij}^2$$

--

- $$Z_{ij}=\frac{\sum_{k=1}^iS_{kj}-\sum_{k=1}^iE_{kj}}{\sqrt{\sum_{k=1}^i}V_{kj}}$$

- $| Z_{ij}|> 1.96$ in absolute value may be an indication of poor model fit

---
# Marginal node monitors 

- Marginal and conditional node monitors check the appropriateness of the probability distributions of each node

``` {r node good fit,warning=FALSE, include=TRUE,message=FALSE,as.is=TRUE,fig.retina=5}
marg.ped <- plot(seq_marg_monitor(dag, diabetes, "PED"))
marg.ped + geom_hline(yintercept = 1.96, linetype='dashed', col = 'red') +  geom_hline(yintercept = -1.96, linetype='dashed', col = 'red')
```

---
```{r large-plot, eval=FALSE}
ggplot(iris) + 
  aes(Sepal.Length, 
      Sepal.Width, 
      color = Species) + 
  geom_point(size = 4) +
  labs(x = 'Sepal Length', 
       y = 'Sepal Width') + 
  theme_minimal() +
  theme(
    text = element_text(size = 24, family = "PT Sans")
  )
```

.plot-callout[
```{r large-plot-callout, ref.label="large-plot", fig.callout=TRUE}
```
]

- The marginal node monitor for PED (diabetes pedigree function) indicates a good fit.

???
Node monitors are used to assess the accuracty of forecasts.
We are most often concerned about this with the 'final outcome' nodes. 
Here the pedigree of diabetes suggests that the forecasts flowing from the model are accurate.
---
# Marginal node monitors 

``` {r node bad fit, warning=FALSE, include=TRUE, echo=FALSE,messages=FALSE,fig.retina=5}
marg.diab <- plot(seq_marg_monitor(dag, diabetes, "DIAB"))
marg.diab + geom_hline(yintercept = 1.96, linetype='dashed', col = 'red') +  geom_hline(yintercept = -1.96, linetype='dashed', col = 'red')
```

- The marginal node monitor for DIAB (diabetes) suggests that the the marginal distribution may be inappropriate for later forecasts.

???
By contrast, the marginal sequential node monitor suggests that the probability distribution for the node  diabetes is not necessarily accurate for later observation in the data. 

---
# Conditional node monitors 

``` {r cond monitor, warning=FALSE, include=TRUE, echo=FALSE,fig.retina=5}
cond.preg <- plot(seq_cond_monitor(dag, diabetes, "PREG")) 
cond.preg + geom_hline(yintercept = 1.96, linetype='dashed', col = 'red') +  geom_hline(yintercept = -1.96, linetype='dashed', col = 'red')
```

- The conditional node monitor for PREG (pregnancy) indicates a poor fit to early forecasts in the data. 


---
# Parent child monitor


```{r pach monitor,warning=FALSE, include=TRUE,fig.retina = 5}
plot(seq_pa_ch_monitor(dag , diabetes , "PREG",pa.names = "AGE", pa.val = "low",alpha=2))+ geom_hline(yintercept = 1.96, linetype='dashed', col = 'red') +  geom_hline(yintercept = -1.96, linetype='dashed', col = 'red')
```

??? 

We can further probe this with the parent child monitor. 
We check all possible values of the parent nodes and find that young women in particular are difficult to predict pregnancies for.

---

class: inverse, center, middle

# Sensitivity

---
The vertex of most interest is \texttt{DIAB} reporting the result of a diabetes test (either positive or negative). As an illustration, we first investigate how the probability of a positive test depends on the variable \texttt{GLUC} = high. 
``` {r bnfit, include = FALSE}
bn <- bn.fit(dag , diabetes)
```
---
``` {r, ,echo=TRUE, out.width='.49\\linewidth', fig.width=5, fig.height=5,fig.show='hold',fig.retina=5}
sens_dc <- sensitivity(bn, interest_node = "DIAB", interest_node_value = "pos", node = "GLUC", value_node = "high", value_parents = NULL, new_value = "all")
sens_dic  <-   sensitivity(bn , interest_node = "DIAB",interest_node_value =   "pos",evidence_nodes = "INS", evidence_states = "low",node = "GLUC", value_node = "high",value_parents = NULL , new_value = "all")
par(mfrow=c(1,2))
plot(sens_dc);plot(sens_dic)  
```

???

The vertex of most interest is DIAB reporting the result of a diabetes test (either positive or negative). As an illustration, we first investigate how the probability of a positive test depends on the variable GLUC = high. 
he plot shows that has the probability of having a high level of glucose increases, then also the probability of a positive test increases.

In the previous example the probability of interest was the marginal probability of a positive test. Similarly, we can assess how generic conditional probabilities are affected by changes in the model. As an illustration, let's consider the conditional probability of a positive test given a low level of insulin and this varies when the probability of a high level of glucose changes. This can be done similarly to the previous code, but now we have to fix the evidence nodes and evidence states inputs.
again the output (conditional) probability of a positive test increases when the probability of a high level of glucose increases. Notice that in this case the increase is non-linear as expected from the results of \citet{Coupe2002}.

---

``` {r, ,echo=FALSE, out.width='.49\\linewidth', fig.width=5, fig.height=5, fig.show='hold',fig.align='center',fig.retina=5}                    
cd_g <- CD(bn , node = "GLUC", value_node = "high",value_parents = NULL , new_value = "all")
cd_d <- CD(bn , node = "DIAB", value_node = "pos",value_parents = c("high","high"), new_value = "all")
par(mfrow=c(1,2))
plot(cd_g); plot(cd_d)
```

???

We now might be interested in knowing how much changes in the probability of high glucose affect the overall probability distribution of the BN. We compute the CD distance using the \texttt{CD} function and the associated \texttt{plot} method. 

The output is given in Figure \ref{fig:CD1} and one can see that the original value of this probability was around 0.5 since the CD is zero.

As an illustration let's consider the CD distance when the conditional probability of a positive diabetes test given a high body mass index and a high glucose is varied.
The plot is reported in Figure \ref{fig:CD2} and we can notice that overall the CD distance is smaller for changes of this probability compared to the one in Figure \ref{fig:CD1}.
---

``` {r snsqury}          
snsqur.diab <- sensquery(bn, interest_node = "DIAB",interest_node_value = "pos", new_value = 0.4,evidence_nodes = "PRES", evidence_states = "high");
knitr::kable(snsqur.diab, format = 'html')
```

???
Last, we may check if probabilities implied by the BN are reasonable. Let's consider as an example the conditional probability of a positive diabetes test given a high pressure level. We can compute this probability using the \texttt{querygrain} function from the \texttt{gRain} package.

---
# Co-Authors 

Manuele Leonelli
IE University, Madrid

Ramsiya Ramanathan
Università di Bologna, Bologna, Italy